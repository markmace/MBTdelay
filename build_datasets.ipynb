{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build composite database for MBTdelay\n",
    "\n",
    "(C) Mark Mace 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERAL INCLUSIONS\n",
    "import numpy as np\n",
    "import glob,os\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# FOR DATES AND TIMES #\n",
    "import time\n",
    "import datetime\n",
    "from dateutil import tz\n",
    "from datetime import timedelta\n",
    "import arrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATIONS=[\"Lechmere\", \"Science Park\", \"North Station\",\n",
    "              \"Haymarket\", \"Government Center\", \"Park Street\", \"Boylston\",\n",
    "             \"Arlington\", \"Copley\",\"Hynes\", \"Kenmore\",\"Fenway\",\"Longwood\",\n",
    "             \"Brookline Village\", \"Brookline Hills\", \"Beaconsfield\", \"Reservoir\",\n",
    "             \"Chestnut Hill\", \"Newton Centre\", \"Newton Highlands\", \"Eliot\",\n",
    "             \"Waban\",\"Woodland\", \"Riverside\"]\n",
    "\n",
    "# GENERAL PURPOSE DATE-TIME FUNCTION\n",
    "from date_time_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC DATE-TIME FUNCTIONS\n",
    "\n",
    "# CONVERTS AB:CD TO AB:00\n",
    "def rounddown_hms(x):\n",
    "    return x[:2]+\":00\"\n",
    "\n",
    "def rounddown_h(x):\n",
    "    return x[:2]\n",
    "\n",
    "# GET HOUR FROM YYYY-MM-DD HH:MM:SS STRING\n",
    "def get_hour(dt_str):\n",
    "    return dt_str[11:13]\n",
    "\n",
    "# GET MONTH FROM YYYY-MM-DD HH:MM:SS STRING\n",
    "def get_month_num(dt_str):\n",
    "    return dt_str[5:7]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WEATHER DATA AND SAVE TO ARRAY\n",
    "# GET FILENAMES \n",
    "weather_data=[]\n",
    "station_weather_files=glob.glob(\"WEATHER_DATA/*.csv\")\n",
    "for file in station_weather_files:\n",
    "    sw_raw=pd.read_csv(file)\n",
    "    station_name,station_lat,station_lon=(file.replace(\".csv\",\"\").replace(\"WEATHER_DATA/\",\"\")).split(\"_\")\n",
    "\n",
    "    weather_data.append([station_name,station_lat,station_lon,sw_raw])\n",
    "    \n",
    "weather_data=np.array(weather_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVENT DATA \n",
    "# ALL FENWAY EVENTS\n",
    "fenway_df=pd.read_csv(\"EVENT_SCHED/all_events.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET RAW HEADWAY DATA\n",
    "# GET FILENAMES \n",
    "headway_data=[]\n",
    "headway_data_files=glob.glob(\"HEADWAY_DATA/Headway*.csv\")\n",
    "for file in headway_data_files:\n",
    "    station_name,station_id=file.replace(\"HEADWAY_DATA/Headway_\",\"\").replace(\".csv\",\"\").split(\"_\")\n",
    "    dt_raw=pd.read_csv(file)\n",
    "    headway_data.append([station_name,station_id,dt_raw])\n",
    "headway_data=np.array(headway_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR STATION DATA WE WANT TO BIN BY THE HOUR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE THAT THIS ISNT NEEDED EVERY TIMES\n",
    "# pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "# GET HEADWAY DATA \n",
    "# BINNING BY THE HOUR\n",
    "def GetAverageHeadway(station_num):\n",
    "\n",
    "    station_name=headway_data[station_num][0]\n",
    "    station_id=headway_data[station_num][1]\n",
    "    headway_data_loc=headway_data[station_num][2].copy() # GET DATAFRAME\n",
    "\n",
    "    # MAKE DATA\n",
    "    headway_data_loc['HEAD_GAP']=headway_data_loc['HDW_T']-headway_data_loc['BNCH_HDW_T']\n",
    "    headway_data_loc['CURR_ARR_DT']=headway_data_loc['CURR_ARR_DT'].astype(int)\n",
    "    \n",
    "    # LOCAL BOSTON TIME #\n",
    "    headway_data_loc['CURR_ARR_DATE_TIME']=headway_data_loc['CURR_ARR_DT'].apply(lambda x: conv_unixts_to_east_hms(x))\n",
    "    \n",
    "    new_date_time=headway_data_loc['CURR_ARR_DATE_TIME'].str.split(\" \", n = 1, expand = True)\n",
    "    headway_data_loc['CURR_ARR_DATE']=new_date_time[0]\n",
    "    headway_data_loc['CURR_ARR_TIME']=new_date_time[1]\n",
    "\n",
    "#     print(headway_data_loc)\n",
    "    \n",
    "    # FIX FORMAT OF TIME TO HH:MM\n",
    "    headway_data_loc['HOUR_BIN']=headway_data_loc['CURR_ARR_TIME'].apply(lambda x: rounddown_hms(x))\n",
    "    headway_data_loc['HOUR_BIN']=headway_data_loc['HOUR_BIN'].astype(str)\n",
    "\n",
    "    # BIN BY THE HOUR\n",
    "    binned_headway=headway_data_loc.groupby(['CURR_ARR_DATE','HOUR_BIN']).agg({'HEAD_GAP':'mean','HDW_T':'mean','BNCH_HDW_T':'mean'}).reset_index()\n",
    "\n",
    "    # FIX FORMAT TO DATETIME TO YYYY-MM-DD HH:MM\n",
    "    binned_headway['CURR_ARR_DATE_TIME']=(binned_headway['CURR_ARR_DATE']).str.cat(binned_headway['HOUR_BIN'],sep=\" \",join='left')\n",
    "    # UNIX FORMAT \n",
    "    binned_headway['U_DATETIME']=binned_headway['CURR_ARR_DATE_TIME'].apply(lambda x: conv_east_to_unixts_hm(x))\n",
    "    binned_headway=binned_headway.sort_values(['U_DATETIME'])\n",
    "\n",
    "    header = [\"U_DATETIME\",\"HEAD_GAP\",\"HDW_T\",\"BNCH_HDW_T\"]\n",
    "    binned_headway.to_csv('DELAYS/'+station_name+'_'+station_id+'.csv',columns=header,index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET AVERAGE HEADWAY TIME\n",
    "for station_num in range(len(headway_data)):\n",
    "    #print(station_num,headway_data[station_num][0],headway_data[station_num][1])\n",
    "    GetAverageHeadway(station_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AVERAGED HEADWAY DATA\n",
    "# GET FILENAMES \n",
    "f_head_data=[]\n",
    "f_head_data_files=glob.glob(\"DELAYS/*.csv\")\n",
    "for file in f_head_data_files:\n",
    "    station_name,station_id=file.replace(\"DELAYS/\",\"\").replace(\".csv\",\"\").split(\"_\")\n",
    "    dt_raw=pd.read_csv(file)\n",
    "    f_head_data.append([station_name,station_id,dt_raw])\n",
    "f_head_data=np.array(f_head_data)\n",
    "\n",
    "station_names=f_head_data[:,0]\n",
    "station_ids=f_head_data[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE FINAL DATA -- COMBINE HEADWAY DELAY, WEATHER, AND FENWAY EVENTS\n",
    "for i in range(len(f_head_data_files)):\n",
    "    station_name=f_head_data[i,0]\n",
    "    station_id=f_head_data[i,1]\n",
    "\n",
    "    #dwell_df=f_dwell_data[i,2]\n",
    "    head_df=f_head_data[i,2].copy()\n",
    "\n",
    "    weather_df=(weather_data[weather_data[:,0]==station_name])[0,3].copy()\n",
    "\n",
    "    merged_1=pd.merge(left=head_df,right=weather_df,     how='left', left_on='U_DATETIME', right_on='U_DATETIME')\n",
    "    merged_final=pd.merge(left=merged_1,right=fenway_df, how='left', left_on='U_DATETIME', right_on='u_datetime')\n",
    "\n",
    "    # GET HUMAN READABLE DATE, HOUR AND MONTH BINS\n",
    "    merged_final['DATETIME'] = merged_final['U_DATETIME'].apply(lambda x:conv_unixts_to_east_hms(x))\n",
    "    merged_final['HOUR_BIN'] = merged_final['DATETIME'].apply(lambda x:get_hour(x))\n",
    "    merged_final['MONTH_BIN'] = merged_final['DATETIME'].apply(lambda x:get_month_num(x))\n",
    "    merged_final['DOW'] = merged_final['U_DATETIME'].apply(lambda x:get_day_of_week_east_unix(x))\n",
    "    # ENCODE PRECIPITATION TYP\n",
    "    catenc=pd.factorize(merged_final['PRECIP_TYP'])\n",
    "    merged_final['PRECIP_TYP_ENC'] = catenc[0]\n",
    "    # FILL NaN FOR EVENT\n",
    "    merged_final['event'] =  merged_final['event'].fillna(0)\n",
    "    \n",
    "    merged_final.to_csv('DS/DS_'+station_name+'_'+station_id+'.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
