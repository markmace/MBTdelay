{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MBTdelay -- model_LinearRegression.ipynb\n",
    "\n",
    "Â© Mark Mace 2019 markfmace@gmail.com\n",
    "\n",
    "Performs linear regression based machine learning on MBTDelay datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERAL INCLUSIONS\n",
    "import numpy as np\n",
    "import glob,os\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# FOR DATES AND TIMES #\n",
    "import time\n",
    "import datetime\n",
    "from dateutil import tz\n",
    "from datetime import timedelta\n",
    "import arrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERT UNIX (utc) TIMESTAMP TO YYYY-mm-dd HH:MM:SS (EASTERN)\n",
    "def conv_unixts_to_east_hms(ts):\n",
    "    east=arrow.Arrow.fromtimestamp(ts).to('US/Eastern')\n",
    "    return east.format('YYYY-MM-DD HH:mm:ss')\n",
    "\n",
    "def get_hour(dt_str):\n",
    "    return dt_str[11:13]\n",
    "\n",
    "def get_month_num(dt_str):\n",
    "    return dt_str[5:7]\n",
    "\n",
    "\n",
    "# RETURNS DAY OF WEEK \n",
    "# M-0, Tu-1, W-2, Th-3 F-4 Sa-6 Su-7\n",
    "# TAKES YYYY-MM-DD HH:MM:SS RETURNS Day (IN WHATEVER TIMEZONE)\n",
    "def get_day_of_week(dt):\n",
    "    dtt = arrow.get(dt)\n",
    "    return dtt.weekday()\n",
    "\n",
    "# TAKES UNIX TS RETURNS Day (IN EASTERN/BOSTON)\n",
    "def get_day_of_week_east_unix(ts):\n",
    "    east=conv_unixts_to_east_hms(ts)\n",
    "    return get_day_of_week(east)\n",
    "    \n",
    "# TAKES UNIX TS RETURNS Day (IN UTC)\n",
    "def get_day_of_week_utc_unix(ts):\n",
    "    utc=conv_unixts_to_utc_hms(ts)\n",
    "    return get_day_of_week(utc)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ML SPECIFIC FUNCTIONS\n",
    "### FOR FEATURE ENGINEERING\n",
    "# ONE HOT ENCODE EVENT -- 1--event, 0--no event\n",
    "def bin_event(x):\n",
    "    x=int(x)\n",
    "    if(x!=0):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# YES OR NO \n",
    "def bin_weather(x):\n",
    "    x=float(x)\n",
    "    if(x>0):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "# BIN PRECIPITATION TYPE\n",
    "def bin_ptype(x):\n",
    "    if(x==1): # None\n",
    "        return 0\n",
    "    else: # rain, snow or sleet\n",
    "        return 0\n",
    "    \n",
    "# BIN IN d_bin SECONDS\n",
    "d_bin=10\n",
    "def bin_delay(x):\n",
    "    x=float(x)\n",
    "    if(x<=0):\n",
    "        return 0\n",
    "    else:\n",
    "        return int(x/d_bin)\n",
    "    \n",
    "#BIN IN t_bin DEGREES\n",
    "t_bin=10\n",
    "def bin_temp(x):\n",
    "    x=float(x)\n",
    "    if(x<=0):\n",
    "        return 0\n",
    "    else:\n",
    "        return int(x/t_bin)\n",
    "    \n",
    "        \n",
    "# PEAK HOUR BIN\n",
    "def bin_peak(x):\n",
    "    x=float(x)\n",
    "    if(6<=x<=10 or 4<=x<=7):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "           \n",
    "# WEEKDAY BIN\n",
    "def bin_weekday(x):\n",
    "    x=float(x)\n",
    "    if(x<5):\n",
    "        return 1 # WEEKDAY\n",
    "    else:\n",
    "        return 0 # WEEKEND\n",
    "    \n",
    "# SEASON\n",
    "def bin_season(x):\n",
    "    x=float(x)\n",
    "    if(x in {1,2,12}):\n",
    "        return 0 # WINTER\n",
    "    elif(x in {3,4,5}):\n",
    "        return 1 # SPRING\n",
    "    elif(x in {9,10,11}):\n",
    "        return 2 # FALL\n",
    "    elif(x in {6,7,8}):\n",
    "        return 3 # SUMMER\n",
    "    else:\n",
    "        print(\"NOT A VALID MONTH\")\n",
    "        return -1 # WRONG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another self-defined eval metric\n",
    "# f(y_true: array, y_pred: array) -> name: string, eval_result: float, is_higher_better: bool\n",
    "# Relative Absolute Error (RAE)\n",
    "def rae(y_true, y_pred):\n",
    "    return 'RAE', np.sum(np.abs(y_pred - y_true)) / np.sum(np.abs(np.mean(y_true) - y_true)), False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'U_DATETIME', 'HEAD_GAP', 'HDW_T', 'BNCH_HDW_T', 'TEMP',\n",
       "       'PRECIP_INT', 'PRECIP_PRO', 'PRECIP_ACC', 'PRECIP_TYP', 'u_datetime',\n",
       "       'event', 'period', 'DN', 'DATETIME', 'HOUR_BIN', 'MONTH_BIN', 'DOW',\n",
       "       'PRECIP_TYP_ENC'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MBTdelay_df=[]\n",
    "ds_files=glob.glob(\"DS/DS_*.csv\")\n",
    "for ds_f in ds_files:\n",
    "#     print(ds_f)\n",
    "    station_name,station_id=ds_f.replace(\"DS/DS_\",\"\").replace(\".csv\",\"\").split(\"_\")\n",
    "    df_temp=pd.read_csv(ds_f)\n",
    "\n",
    "    MBTdelay_df.append([station_name,station_id,df_temp])\n",
    "    \n",
    "    # ENCODE PRECIP TYPE AS NUMBER\n",
    "MBTdelay_df=np.array(MBTdelay_df)\n",
    "MBTdelay_df[0][2].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESULTS OF THE FUNCTION BELOW #\n",
    "f_combo_1=[0,0,1,0,1,0,1,0,0]\n",
    "f_combo_2=[0,1,1,0,1,0,0,0,0] # <-- THIS IS THE BEST COMBO\n",
    "\n",
    "# FEATURE ENGINEER DATA AND PERFORM TRAIN-TEST SPLIT\n",
    "def feature_engineer_and_split(loc_df,EVENT_FLAG,SNOW_YN_FLAG,RAIN_YN_FLAG,\n",
    "          WEEKDAY_FLAG,PRECIP_TYP_FLAG,PEAK_FLAG,DELAY_FLAG,SEASON_FLAG,TEMP_FLAG,split_perc,shuffle_flag):\n",
    "    \n",
    "#     print(np.mean(test_df['HEAD_GAP']))\n",
    "    fe_df=loc_df[np.isfinite(loc_df['TEMP'])].copy()\n",
    "\n",
    "    if(EVENT_FLAG==1):\n",
    "        fe_df['event']=fe_df['event'].apply(lambda x: bin_weather(x))\n",
    "\n",
    "    if(SNOW_YN_FLAG==1):\n",
    "        fe_df['PRECIP_ACC']=fe_df['PRECIP_ACC'].apply(lambda x: bin_weather(x))\n",
    "\n",
    "    if(RAIN_YN_FLAG==1):\n",
    "        fe_df['PRECIP_INT']=fe_df['PRECIP_INT'].apply(lambda x: bin_weather(x))\n",
    "\n",
    "    if(WEEKDAY_FLAG==1):\n",
    "        fe_df['DOW']=fe_df['DOW'].apply(lambda x: bin_weekday(x))\n",
    "        \n",
    "    if(PRECIP_TYP_FLAG==1):\n",
    "        fe_df['PRECIP_TYP_ENC']=fe_df['PRECIP_TYP_ENC'].apply(lambda x: bin_ptype(x))\n",
    "\n",
    "    if(PEAK_FLAG==1):\n",
    "        fe_df['HOUR_BIN']=fe_df['HOUR_BIN'].apply(lambda x: bin_peak(x))\n",
    "\n",
    "    if(DELAY_FLAG==1):\n",
    "        fe_df['HEAD_GAP']=fe_df['HEAD_GAP'].apply(lambda x: bin_delay(x))\n",
    "\n",
    "    if(SEASON_FLAG==1):\n",
    "        fe_df['MONTH_BIN']=fe_df['MONTH_BIN'].apply(lambda x: bin_season(x))\n",
    "        \n",
    "    if(TEMP_FLAG==1):\n",
    "        fe_df['TEMP']=fe_df['TEMP'].apply(lambda x: bin_temp(x))\n",
    "\n",
    "    # NOT INCLUDING PRECIP TYPE #\n",
    "    all_x=np.transpose(np.array([fe_df['HOUR_BIN'], fe_df['DOW'], fe_df['MONTH_BIN'],\n",
    "                                fe_df['event'],\n",
    "                                fe_df['PRECIP_INT'], fe_df['PRECIP_ACC'], \n",
    "                                fe_df['PRECIP_PRO'], fe_df['TEMP']],dtype=np.float32))\n",
    "\n",
    "    all_y=np.array([fe_df['HEAD_GAP']],dtype=np.float32)[0]\n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(all_x, all_y, test_size=split_perc, random_state=0,shuffle=shuffle_flag)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Starting predicting...\n",
      "The rmse of prediction is: 16.36712503717198\n",
      "The rae of prediction is: 0.9742725\n",
      "Variance score:  0.03435810547181506\n"
     ]
    }
   ],
   "source": [
    "## THIS IS JUST FOR TESTING ##\n",
    "\n",
    "# TEST STATION NUMBER # \n",
    "station_num_id=3\n",
    "\n",
    "test_size=0.2\n",
    "\n",
    "# LOCAL LOAD DATAFRAME \n",
    "station_name=MBTdelay_df[station_num_id][0]\n",
    "station_id=MBTdelay_df[station_num_id][1]\n",
    "test_df=MBTdelay_df[station_num_id][2].copy()\n",
    "test_df = test_df[np.isfinite(test_df['HEAD_GAP'])]\n",
    "\n",
    "X_train, X_test, y_train, y_test=feature_engineer_and_split(test_df, 0,1,1,0,1,0,1,0,0,test_size,True)\n",
    "# X_train, X_test, y_train, y_test=feature_engineer_and_split(df_loc,0,1,1,0,1,0,1,0,0,0.2) # FEATURE ENGINEERED\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "print('Saving model...')\n",
    "# save model to file\n",
    "pickle.dump(regr, open('NEW_LR_MODEL/'+station_name+'_'+station_id+'.pk', 'wb'))\n",
    "    \n",
    "\n",
    "print('Starting predicting...')\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = regr.predict(X_test)\n",
    "\n",
    "# eval\n",
    "print('The rmse of prediction is:', mean_squared_error(y_test, y_pred) ** 0.5)\n",
    "print('The rae of prediction is:', rae(y_test, y_pred)[1])\n",
    "print('Variance score: ',r2_score(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "Saving model...\n",
      "Starting predicting...\n"
     ]
    }
   ],
   "source": [
    "# BUFFERS FOR ANALYTICS\n",
    "data_metrics=[]\n",
    "model_outcomes=[]\n",
    "\n",
    "# TRAIN-TEST SPLIT\n",
    "test_size=0.2\n",
    "\n",
    "# RUN MODEL FOR ALL STATIOS AND SAVE TO FILE #\n",
    "for station_num_id in range(len(MBTdelay_df)):\n",
    "    \n",
    "    # LOAD DATAFRAME \n",
    "    station_name=MBTdelay_df[station_num_id][0]\n",
    "    station_id=MBTdelay_df[station_num_id][1]\n",
    "    test_df=MBTdelay_df[station_num_id][2].copy()\n",
    "\n",
    "    # SIMPLE STATS FOR DATA FOR A STATION\n",
    "    gap_mode=stats.mode(test_df['HEAD_GAP'].values)\n",
    "    gap_mean=np.mean(test_df['HEAD_GAP'])\n",
    "    gap_mean_unc=np.std(test_df['HEAD_GAP'])/np.sqrt(len(test_df['HEAD_GAP']))\n",
    "    \n",
    "    # SAVE METRICS TO ARRAY \n",
    "    data_metrics.append([station_name,station_id,\n",
    "                    gap_mode,\n",
    "                    gap_mean,\n",
    "                    gap_mean_unc\n",
    "                    ])\n",
    "    \n",
    "    # GENERATE TEST-TRAIN SPLIT -- USES FEATURE ENGINEERING DETERMINED PREVIOUSLY #\n",
    "    X_train, X_test, y_train, y_test=feature_engineer_and_split(test_df, 0,1,1,0,1,0,0,0,0, test_size, True)\n",
    "    \n",
    "    # Create linear regression object\n",
    "    regr = linear_model.LinearRegression()\n",
    "\n",
    "    # Train the model using the training sets\n",
    "    regr.fit(X_train, y_train)\n",
    "\n",
    "    print('Saving model...')\n",
    "    # save model to file\n",
    "    pickle.dump(regr, open('LR_MODEL/'+station_name+'_'+station_id+'.pk', 'wb'))\n",
    "\n",
    "    print('Starting predicting...')\n",
    "\n",
    "    # Make predictions using the testing set\n",
    "    y_pred = regr.predict(X_test)\n",
    "\n",
    "    # EVALUATE METRICS\n",
    "    mae=metrics.mean_absolute_error(y_test, y_pred)\n",
    "    mse=metrics.mean_squared_error(y_test, y_pred)\n",
    "    rmse=np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "    r2=r2_score(y_test,y_pred)\n",
    "    \n",
    "    # SAVE MODEL METRICS\n",
    "    model_outcomes.append([station_name,station_id,mae,mse,rmse,r2])\n",
    "\n",
    "model_outcomes=np.array(model_outcomes)\n",
    "\n",
    "mo_df=pd.DataFrame({'station_name': model_outcomes[:, 0], \n",
    "                    'station_id': model_outcomes[:, 1], \n",
    "                    'mae': model_outcomes[:, 2], \n",
    "                    'mse': model_outcomes[:, 3], \n",
    "                    'rmse': model_outcomes[:, 4], \n",
    "                    'r2': model_outcomes[:, 5]})\n",
    "\n",
    "mo_df.to_csv('LR_MODEL/Outcomes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
